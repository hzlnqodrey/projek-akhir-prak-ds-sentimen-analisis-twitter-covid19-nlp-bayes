{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Projek Akhir Praktikum Data Science**\n",
    "\n",
    "> Analisis Sentimen Mengenai Vaksin COVID-19 Di Indonesia Menggunakan Metode Naive Bayes Classifier dan NLP Pada Sosial Media Twitter\n",
    "\n",
    "**Oleh Kelompok 2 :**\n",
    "1. Hazlan Muhammad Qodri (123190080) @hzlnqodrey\n",
    "2. Elisia Dwi Rahayu (123190062) @elisiadwirahayu\n",
    "3. Shania Septika Inayasari (123190055) @shaniainayasari\n",
    "\n",
    "**Penjelasan Projek :**\n",
    "\n",
    "Adapun pada penelitian menekankan kepada sentimen masyarakat terhadap mengenai vaksin COVID-19. Proses analisisnya akan dilakukan berdasarkan tweet yang menyertakan tagar vaksin dan pencarian di twitter dengan keyword vaksin covid 19."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **1. Scraping Data from Twitter**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install snscrape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import snscrape.modules.twitter as sntwitter\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get All Covid Sentiment Data from January 1st, 2020 until November 1st, 2022\n",
    "query = \"covid since:2020-01-01 until:2022-11-01 lang:id\"\n",
    "limit = 2000 # limit 50k rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets = []\n",
    "\n",
    "for tweet in sntwitter.TwitterSearchScraper(query).get_items():\n",
    "    if len(tweets) == limit:\n",
    "        break\n",
    "    else:\n",
    "        tweets.append([\n",
    "            tweet.date,\n",
    "            tweet.username,\n",
    "            tweet.content\n",
    "        ])\n",
    "\n",
    "filename = 'tweets_covid_dataset_2k_raw_noindex.csv'\n",
    "tweets_df = pd.DataFrame(tweets, columns=['Tanggal', 'Username', 'Text'])\n",
    "tweets_df.to_csv(filename, index=False)\n",
    "print('Scraping has completed!')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **2. Wrangling Data** (Preprocessing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install tweet-preprocessor\n",
    "%pip install textblob\n",
    "%pip install wordcloud\n",
    "%pip install nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to C:\\Users\\HAZLAN M\n",
      "[nltk_data]     QODRI\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import preprocessor as preproc\n",
    "from textblob import TextBlob\n",
    "from nltk.stem import PorterStemmer\n",
    "from nltk.tokenize import word_tokenize\n",
    "import nltk\n",
    "nltk.download('punkt')\n",
    "import csv\n",
    "import string\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get data from dataset\n",
    "data = pd.read_csv('https://raw.githubusercontent.com/hzlnqodrey/projek-akhir-prak-ds-sentimen-analisis-twitter-covid19-nlp-bayes/main/data_csv/tweets_covid_dataset_2k_raw_noindex.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.sample(n=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 1. Case Folding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['Text'] = data['Text'].str.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Case Folding Result : \\n')\n",
    "data.sample(n=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 2. Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cleaning overall\n",
    "def preprocessing_data(x):\n",
    "    return preproc.clean(x)\n",
    "\n",
    "data['Text'] = data['Text'].apply(preprocessing_data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Cleaning Result : \\n')\n",
    "data.sample(n=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cleaning Result : \n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Tanggal</th>\n",
       "      <th>Username</th>\n",
       "      <th>Text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>815</th>\n",
       "      <td>2022-10-31 11:44:36+00:00</td>\n",
       "      <td>beritajatimcom</td>\n",
       "      <td>posko covid di sampang masih aktif warga diimb...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>2022-10-31 23:24:47+00:00</td>\n",
       "      <td>NisakMs</td>\n",
       "      <td>lamalama jadi dr umum ama sp di jkt harus ment...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>107</th>\n",
       "      <td>2022-10-31 21:36:46+00:00</td>\n",
       "      <td>SINDOnews</td>\n",
       "      <td>kasus covid-19 kembali meningkat malaysia anju...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>110</th>\n",
       "      <td>2022-10-31 21:17:31+00:00</td>\n",
       "      <td>nisailmiaa</td>\n",
       "      <td>kdg mikir andai covid iki gak ono what college...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1249</th>\n",
       "      <td>2022-10-31 08:54:34+00:00</td>\n",
       "      <td>BergemaRock</td>\n",
       "      <td>kaga percaya covad covid dan vaksin</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        Tanggal        Username  \\\n",
       "815   2022-10-31 11:44:36+00:00  beritajatimcom   \n",
       "36    2022-10-31 23:24:47+00:00         NisakMs   \n",
       "107   2022-10-31 21:36:46+00:00       SINDOnews   \n",
       "110   2022-10-31 21:17:31+00:00      nisailmiaa   \n",
       "1249  2022-10-31 08:54:34+00:00     BergemaRock   \n",
       "\n",
       "                                                   Text  \n",
       "815   posko covid di sampang masih aktif warga diimb...  \n",
       "36    lamalama jadi dr umum ama sp di jkt harus ment...  \n",
       "107   kasus covid-19 kembali meningkat malaysia anju...  \n",
       "110   kdg mikir andai covid iki gak ono what college...  \n",
       "1249                kaga percaya covad covid dan vaksin  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# cleaning remove_comments_special\n",
    "def remove_comments_special(text):\n",
    "    # remove tab, new line, and back slice\n",
    "    text = text.replace('\\\\t', \" \").replace('\\\\n', \" \").replace(\n",
    "        '\\\\u', \" \").replace('\\\\', \" \").replace('.', \" \")\n",
    "    # remove non ASCII (emoticon, chinese word, .etc)\n",
    "    text = text.encode('ascii', 'replace').decode('ascii')\n",
    "    # remove mention, link, hashtag\n",
    "    text = ' '.join(\n",
    "        re.sub(\"([@#][A-Za-z0-9]+)|(\\w+:\\/\\/\\S+)\", \" \", text).split())\n",
    "    # remove ascii decoded\n",
    "    text = ' '.join(\n",
    "        re.sub(\"amp; \", \" \", text).split())\n",
    "    text = ' '.join(\n",
    "        re.sub(\"lt; \", \" \", text).split())\n",
    "    text = ' '.join(\n",
    "        re.sub(\"gt; \", \" \", text).split())\n",
    "    # remove single char\n",
    "    text = ' '.join(\n",
    "        re.sub(r\"\\b[a-zA-Z]\\b\", \" \", text).split())\n",
    "    return text\n",
    "\n",
    "data['Text'] = data['Text'].apply(remove_comments_special)\n",
    "\n",
    "# remove symbol\n",
    "def remove_symbol(text):\n",
    "    text = ''.join(\n",
    "        re.sub(r\"[\\!\\@\\#\\$\\%\\^\\&\\*\\(\\)\\?\\,\\\"\\|\\:]+\", \"\", text)\n",
    "    )\n",
    "    return text\n",
    "\n",
    "data['Text'] = data['Text'].apply(remove_symbol)\n",
    "\n",
    "# remove punctuation\n",
    "def remove_punctuation(text):\n",
    "    return text.translate(str.maketrans(\"\", \"\", string.punctuation))\n",
    "\n",
    "\n",
    "print('Cleaning Result : \\n')\n",
    "data.sample(n=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 3. Tokenizing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize_data(text):\n",
    "    return word_tokenize(text)\n",
    "\n",
    "data['Text_Clean'] = data['Text'].apply(tokenize_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Tokenizing Result : \\n')\n",
    "data.sample(n=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 4. Filtering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Tanggal</th>\n",
       "      <th>Username</th>\n",
       "      <th>Text</th>\n",
       "      <th>Text_Clean</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2022-10-31 23:59:58+00:00</td>\n",
       "      <td>lordkuyang</td>\n",
       "      <td>dulu di barat upn ada warung kayuh bambai bumb...</td>\n",
       "      <td>[dulu, di, barat, upn, ada, warung, kayuh, bam...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2022-10-31 23:58:49+00:00</td>\n",
       "      <td>s_h_y_l_l_a</td>\n",
       "      <td>segala sakit yg disalahin vaksin covid lieur</td>\n",
       "      <td>[segala, sakit, yang , disalahin, vaksin, covi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2022-10-31 23:58:14+00:00</td>\n",
       "      <td>kunsh72</td>\n",
       "      <td>bukankah kamu dulu bagian rezim namun setelah ...</td>\n",
       "      <td>[bukankah, kamu, dulu, bagian, rezim, namun, s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2022-10-31 23:57:58+00:00</td>\n",
       "      <td>erni076</td>\n",
       "      <td>aku kan ganti lama dulu sebelum covid menyeran...</td>\n",
       "      <td>[saya, kan, ganti, lama, dulu, sebelum, covid,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2022-10-31 23:57:38+00:00</td>\n",
       "      <td>KENTUSIAS</td>\n",
       "      <td>trus masku kena covid lagi kek yah udah endemi...</td>\n",
       "      <td>[terus , masku, kena, covid, lagi, kek, yah, s...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     Tanggal     Username  \\\n",
       "0  2022-10-31 23:59:58+00:00   lordkuyang   \n",
       "1  2022-10-31 23:58:49+00:00  s_h_y_l_l_a   \n",
       "2  2022-10-31 23:58:14+00:00      kunsh72   \n",
       "3  2022-10-31 23:57:58+00:00      erni076   \n",
       "4  2022-10-31 23:57:38+00:00    KENTUSIAS   \n",
       "\n",
       "                                                Text  \\\n",
       "0  dulu di barat upn ada warung kayuh bambai bumb...   \n",
       "1       segala sakit yg disalahin vaksin covid lieur   \n",
       "2  bukankah kamu dulu bagian rezim namun setelah ...   \n",
       "3  aku kan ganti lama dulu sebelum covid menyeran...   \n",
       "4  trus masku kena covid lagi kek yah udah endemi...   \n",
       "\n",
       "                                          Text_Clean  \n",
       "0  [dulu, di, barat, upn, ada, warung, kayuh, bam...  \n",
       "1  [segala, sakit, yang , disalahin, vaksin, covi...  \n",
       "2  [bukankah, kamu, dulu, bagian, rezim, namun, s...  \n",
       "3  [saya, kan, ganti, lama, dulu, sebelum, covid,...  \n",
       "4  [terus , masku, kena, covid, lagi, kek, yah, s...  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Filtering | Singkatan Indo\n",
    "normalizad_word = pd.read_csv(\n",
    "    \"https://raw.githubusercontent.com/meisaputri21/Indonesian-Twitter-Emotion-Dataset/master/kamus_singkatan.csv\", sep=\";\", header=None)\n",
    "normalizad_word_dict = {}\n",
    "\n",
    "for index, row in normalizad_word.iterrows():\n",
    "    if row[0] not in normalizad_word_dict:\n",
    "        normalizad_word_dict[row[0]] = row[1]\n",
    "\n",
    "\n",
    "def normalized_term(document):\n",
    "    return [normalizad_word_dict[term] if term in normalizad_word_dict else term for term in document]\n",
    "\n",
    "\n",
    "data['Text_Clean'] = data['Text_Clean'].apply(normalized_term)\n",
    "data.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filtering | Stop Word\n",
    "list_stopwords = (['yang', 'untuk', 'pada', 'ke', 'para', 'namun', 'menurut', 'antara', 'seperti', 'jika', 'jika', 'sehingga', 'mungkin', 'kembali', 'dan', 'ini', 'karena', 'oleh', 'saat', 'sekitar', 'bagi', 'serta', 'di', 'dari', 'sebagai', 'hal', 'ketika', 'adalah', 'itu', 'dalam', 'bahwa', 'atau', 'dengan', 'akan', 'juga', 'kalau', 'ada', 'terhadap', 'secara', 'agar', 'lain', 'jadi', 'yang ', 'sudah', 'sudah begitu', 'mengapa', 'kenapa', 'yaitu', 'yakni', 'daripada', 'itulah', 'lagi', 'maka', 'tentang', 'demi', 'dimana', 'kemana', 'pula', 'sambil', 'sebelum', 'sesudah', 'supaya', 'guna', 'kah', 'pun', 'sampai', 'sedangkan', 'selagi',\n",
    "                  'sementara', 'tetapi', 'apakah', 'sebab', 'selain', 'seolah', 'seraya', 'seterusnya', 'dsb', 'dst', 'dll', 'dahulu', 'dulunya', 'anu', 'demikian', 'tapi', 'juga', 'mari', 'nanti', 'melainkan', 'oh', 'ok', 'sebetulnya', 'setiap', 'sesuatu', 'pasti', 'saja', 'toh', 'ya', 'walau', 'apalagi', 'bagaimanapun', 'yg', 'dg', 'rt', 'dgn', 'ny', 'd', 'klo', 'kalo', 'amp', 'biar', 'bikin', 'bilang', 'krn', 'nya', 'nih', 'sih', 'ah', 'ssh', 'om', 'ah', 'si', 'tau', 'tuh', 'utk', 'ya', 'cek', 'jd', 'aja', 't', 'nyg', 'hehe', 'pen', 'nan', 'loh', 'rt', '&amp', 'yah', 'ni', 'ret', 'za', 'nak', 'haa', 'zaa', 'maa', 'lg', 'eh', 'hmm', 'kali'])\n",
    "\n",
    "list_stopwords = set(list_stopwords)\n",
    "\n",
    "\n",
    "def stopwords_removal(words):\n",
    "    return [word for word in words if word not in list_stopwords]\n",
    "\n",
    "\n",
    "data['Text_Clean'] = data['Text_Clean'].apply(stopwords_removal)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Tanggal</th>\n",
       "      <th>Username</th>\n",
       "      <th>Text</th>\n",
       "      <th>Text_Clean</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2022-10-31 23:59:58+00:00</td>\n",
       "      <td>lordkuyang</td>\n",
       "      <td>dulu di barat upn ada warung kayuh bambai bumb...</td>\n",
       "      <td>[dulu, barat, upn, warung, kayuh, bambai, bumb...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2022-10-31 23:58:49+00:00</td>\n",
       "      <td>s_h_y_l_l_a</td>\n",
       "      <td>segala sakit yg disalahin vaksin covid lieur</td>\n",
       "      <td>[segala, sakit, disalahin, vaksin, covid, lieur]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2022-10-31 23:58:14+00:00</td>\n",
       "      <td>kunsh72</td>\n",
       "      <td>bukankah kamu dulu bagian rezim namun setelah ...</td>\n",
       "      <td>[bukankah, kamu, dulu, bagian, rezim, setelah,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2022-10-31 23:57:58+00:00</td>\n",
       "      <td>erni076</td>\n",
       "      <td>aku kan ganti lama dulu sebelum covid menyeran...</td>\n",
       "      <td>[saya, kan, ganti, lama, dulu, covid, menyeran...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2022-10-31 23:57:38+00:00</td>\n",
       "      <td>KENTUSIAS</td>\n",
       "      <td>trus masku kena covid lagi kek yah udah endemi...</td>\n",
       "      <td>[terus , masku, kena, covid, kek, sudah , ende...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     Tanggal     Username  \\\n",
       "0  2022-10-31 23:59:58+00:00   lordkuyang   \n",
       "1  2022-10-31 23:58:49+00:00  s_h_y_l_l_a   \n",
       "2  2022-10-31 23:58:14+00:00      kunsh72   \n",
       "3  2022-10-31 23:57:58+00:00      erni076   \n",
       "4  2022-10-31 23:57:38+00:00    KENTUSIAS   \n",
       "\n",
       "                                                Text  \\\n",
       "0  dulu di barat upn ada warung kayuh bambai bumb...   \n",
       "1       segala sakit yg disalahin vaksin covid lieur   \n",
       "2  bukankah kamu dulu bagian rezim namun setelah ...   \n",
       "3  aku kan ganti lama dulu sebelum covid menyeran...   \n",
       "4  trus masku kena covid lagi kek yah udah endemi...   \n",
       "\n",
       "                                          Text_Clean  \n",
       "0  [dulu, barat, upn, warung, kayuh, bambai, bumb...  \n",
       "1   [segala, sakit, disalahin, vaksin, covid, lieur]  \n",
       "2  [bukankah, kamu, dulu, bagian, rezim, setelah,...  \n",
       "3  [saya, kan, ganti, lama, dulu, covid, menyeran...  \n",
       "4  [terus , masku, kena, covid, kek, sudah , ende...  "
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sambungin_kata(text):\n",
    "    text = ' '.join(text)\n",
    "    return text\n",
    "\n",
    "data['Text_Clean_Sambung'] = data['Text_Clean'].apply(sambungin_kata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Tanggal</th>\n",
       "      <th>Username</th>\n",
       "      <th>Text</th>\n",
       "      <th>Text_Clean</th>\n",
       "      <th>Text_Clean_Sambung</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2022-10-31 23:59:58+00:00</td>\n",
       "      <td>lordkuyang</td>\n",
       "      <td>dulu di barat upn ada warung kayuh bambai bumb...</td>\n",
       "      <td>[dulu, barat, upn, warung, kayuh, bambai, bumb...</td>\n",
       "      <td>dulu barat upn warung kayuh bambai bumbu haban...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2022-10-31 23:58:49+00:00</td>\n",
       "      <td>s_h_y_l_l_a</td>\n",
       "      <td>segala sakit yg disalahin vaksin covid lieur</td>\n",
       "      <td>[segala, sakit, disalahin, vaksin, covid, lieur]</td>\n",
       "      <td>segala sakit disalahin vaksin covid lieur</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2022-10-31 23:58:14+00:00</td>\n",
       "      <td>kunsh72</td>\n",
       "      <td>bukankah kamu dulu bagian rezim namun setelah ...</td>\n",
       "      <td>[bukankah, kamu, dulu, bagian, rezim, setelah,...</td>\n",
       "      <td>bukankah kamu dulu bagian rezim setelah terdep...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2022-10-31 23:57:58+00:00</td>\n",
       "      <td>erni076</td>\n",
       "      <td>aku kan ganti lama dulu sebelum covid menyeran...</td>\n",
       "      <td>[saya, kan, ganti, lama, dulu, covid, menyeran...</td>\n",
       "      <td>saya kan ganti lama dulu covid menyerang sudah...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2022-10-31 23:57:38+00:00</td>\n",
       "      <td>KENTUSIAS</td>\n",
       "      <td>trus masku kena covid lagi kek yah udah endemi...</td>\n",
       "      <td>[terus , masku, kena, covid, kek, sudah , ende...</td>\n",
       "      <td>terus  masku kena covid kek sudah  endemi masi ae</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1995</th>\n",
       "      <td>2022-10-31 04:14:37+00:00</td>\n",
       "      <td>Rakhalandikas</td>\n",
       "      <td>iya aku lebih merujuk kepada kerumunan faktor ...</td>\n",
       "      <td>[iya, saya, lebih, merujuk, kepada, kerumunan,...</td>\n",
       "      <td>iya saya lebih merujuk kepada kerumunan faktor...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1996</th>\n",
       "      <td>2022-10-31 04:14:23+00:00</td>\n",
       "      <td>DumaiBarat</td>\n",
       "      <td>ayo vaksinagar tubuh terlindungi dari covid-19...</td>\n",
       "      <td>[ayo, vaksinagar, tubuh, terlindungi, covid-19...</td>\n",
       "      <td>ayo vaksinagar tubuh terlindungi covid-19 ayo ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1997</th>\n",
       "      <td>2022-10-31 04:14:23+00:00</td>\n",
       "      <td>TyasAru14236593</td>\n",
       "      <td>bahkan kalo mau liat di lingkungan sekitar jug...</td>\n",
       "      <td>[bahkan, kalau , mau, liat, lingkungan, banyak...</td>\n",
       "      <td>bahkan kalau  mau liat lingkungan banyak tetan...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1998</th>\n",
       "      <td>2022-10-31 04:13:44+00:00</td>\n",
       "      <td>rezkyheidi</td>\n",
       "      <td>min ada info lokasi tersedia untuk booster vak...</td>\n",
       "      <td>[min, info, lokasi, tersedia, booster, vaksin,...</td>\n",
       "      <td>min info lokasi tersedia booster vaksin covid</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1999</th>\n",
       "      <td>2022-10-31 04:13:18+00:00</td>\n",
       "      <td>everydaykkkk</td>\n",
       "      <td>saya puji tuhan ngga pernah kena covid bu tapi...</td>\n",
       "      <td>[saya, puji, tuhan, tidak , pernah, kena, covi...</td>\n",
       "      <td>saya puji tuhan tidak  pernah kena covid bu ja...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2000 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                        Tanggal         Username  \\\n",
       "0     2022-10-31 23:59:58+00:00       lordkuyang   \n",
       "1     2022-10-31 23:58:49+00:00      s_h_y_l_l_a   \n",
       "2     2022-10-31 23:58:14+00:00          kunsh72   \n",
       "3     2022-10-31 23:57:58+00:00          erni076   \n",
       "4     2022-10-31 23:57:38+00:00        KENTUSIAS   \n",
       "...                         ...              ...   \n",
       "1995  2022-10-31 04:14:37+00:00    Rakhalandikas   \n",
       "1996  2022-10-31 04:14:23+00:00       DumaiBarat   \n",
       "1997  2022-10-31 04:14:23+00:00  TyasAru14236593   \n",
       "1998  2022-10-31 04:13:44+00:00       rezkyheidi   \n",
       "1999  2022-10-31 04:13:18+00:00     everydaykkkk   \n",
       "\n",
       "                                                   Text  \\\n",
       "0     dulu di barat upn ada warung kayuh bambai bumb...   \n",
       "1          segala sakit yg disalahin vaksin covid lieur   \n",
       "2     bukankah kamu dulu bagian rezim namun setelah ...   \n",
       "3     aku kan ganti lama dulu sebelum covid menyeran...   \n",
       "4     trus masku kena covid lagi kek yah udah endemi...   \n",
       "...                                                 ...   \n",
       "1995  iya aku lebih merujuk kepada kerumunan faktor ...   \n",
       "1996  ayo vaksinagar tubuh terlindungi dari covid-19...   \n",
       "1997  bahkan kalo mau liat di lingkungan sekitar jug...   \n",
       "1998  min ada info lokasi tersedia untuk booster vak...   \n",
       "1999  saya puji tuhan ngga pernah kena covid bu tapi...   \n",
       "\n",
       "                                             Text_Clean  \\\n",
       "0     [dulu, barat, upn, warung, kayuh, bambai, bumb...   \n",
       "1      [segala, sakit, disalahin, vaksin, covid, lieur]   \n",
       "2     [bukankah, kamu, dulu, bagian, rezim, setelah,...   \n",
       "3     [saya, kan, ganti, lama, dulu, covid, menyeran...   \n",
       "4     [terus , masku, kena, covid, kek, sudah , ende...   \n",
       "...                                                 ...   \n",
       "1995  [iya, saya, lebih, merujuk, kepada, kerumunan,...   \n",
       "1996  [ayo, vaksinagar, tubuh, terlindungi, covid-19...   \n",
       "1997  [bahkan, kalau , mau, liat, lingkungan, banyak...   \n",
       "1998  [min, info, lokasi, tersedia, booster, vaksin,...   \n",
       "1999  [saya, puji, tuhan, tidak , pernah, kena, covi...   \n",
       "\n",
       "                                     Text_Clean_Sambung  \n",
       "0     dulu barat upn warung kayuh bambai bumbu haban...  \n",
       "1             segala sakit disalahin vaksin covid lieur  \n",
       "2     bukankah kamu dulu bagian rezim setelah terdep...  \n",
       "3     saya kan ganti lama dulu covid menyerang sudah...  \n",
       "4     terus  masku kena covid kek sudah  endemi masi ae  \n",
       "...                                                 ...  \n",
       "1995  iya saya lebih merujuk kepada kerumunan faktor...  \n",
       "1996  ayo vaksinagar tubuh terlindungi covid-19 ayo ...  \n",
       "1997  bahkan kalau  mau liat lingkungan banyak tetan...  \n",
       "1998      min info lokasi tersedia booster vaksin covid  \n",
       "1999  saya puji tuhan tidak  pernah kena covid bu ja...  \n",
       "\n",
       "[2000 rows x 5 columns]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.drop(['Text_Clean'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Tanggal</th>\n",
       "      <th>Username</th>\n",
       "      <th>Text</th>\n",
       "      <th>Text_Clean_Sambung</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2022-10-31 23:59:58+00:00</td>\n",
       "      <td>lordkuyang</td>\n",
       "      <td>dulu di barat upn ada warung kayuh bambai bumb...</td>\n",
       "      <td>dulu barat upn warung kayuh bambai bumbu haban...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2022-10-31 23:58:49+00:00</td>\n",
       "      <td>s_h_y_l_l_a</td>\n",
       "      <td>segala sakit yg disalahin vaksin covid lieur</td>\n",
       "      <td>segala sakit disalahin vaksin covid lieur</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2022-10-31 23:58:14+00:00</td>\n",
       "      <td>kunsh72</td>\n",
       "      <td>bukankah kamu dulu bagian rezim namun setelah ...</td>\n",
       "      <td>bukankah kamu dulu bagian rezim setelah terdep...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2022-10-31 23:57:58+00:00</td>\n",
       "      <td>erni076</td>\n",
       "      <td>aku kan ganti lama dulu sebelum covid menyeran...</td>\n",
       "      <td>saya kan ganti lama dulu covid menyerang sudah...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2022-10-31 23:57:38+00:00</td>\n",
       "      <td>KENTUSIAS</td>\n",
       "      <td>trus masku kena covid lagi kek yah udah endemi...</td>\n",
       "      <td>terus  masku kena covid kek sudah  endemi masi ae</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1995</th>\n",
       "      <td>2022-10-31 04:14:37+00:00</td>\n",
       "      <td>Rakhalandikas</td>\n",
       "      <td>iya aku lebih merujuk kepada kerumunan faktor ...</td>\n",
       "      <td>iya saya lebih merujuk kepada kerumunan faktor...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1996</th>\n",
       "      <td>2022-10-31 04:14:23+00:00</td>\n",
       "      <td>DumaiBarat</td>\n",
       "      <td>ayo vaksinagar tubuh terlindungi dari covid-19...</td>\n",
       "      <td>ayo vaksinagar tubuh terlindungi covid-19 ayo ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1997</th>\n",
       "      <td>2022-10-31 04:14:23+00:00</td>\n",
       "      <td>TyasAru14236593</td>\n",
       "      <td>bahkan kalo mau liat di lingkungan sekitar jug...</td>\n",
       "      <td>bahkan kalau  mau liat lingkungan banyak tetan...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1998</th>\n",
       "      <td>2022-10-31 04:13:44+00:00</td>\n",
       "      <td>rezkyheidi</td>\n",
       "      <td>min ada info lokasi tersedia untuk booster vak...</td>\n",
       "      <td>min info lokasi tersedia booster vaksin covid</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1999</th>\n",
       "      <td>2022-10-31 04:13:18+00:00</td>\n",
       "      <td>everydaykkkk</td>\n",
       "      <td>saya puji tuhan ngga pernah kena covid bu tapi...</td>\n",
       "      <td>saya puji tuhan tidak  pernah kena covid bu ja...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2000 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                        Tanggal         Username  \\\n",
       "0     2022-10-31 23:59:58+00:00       lordkuyang   \n",
       "1     2022-10-31 23:58:49+00:00      s_h_y_l_l_a   \n",
       "2     2022-10-31 23:58:14+00:00          kunsh72   \n",
       "3     2022-10-31 23:57:58+00:00          erni076   \n",
       "4     2022-10-31 23:57:38+00:00        KENTUSIAS   \n",
       "...                         ...              ...   \n",
       "1995  2022-10-31 04:14:37+00:00    Rakhalandikas   \n",
       "1996  2022-10-31 04:14:23+00:00       DumaiBarat   \n",
       "1997  2022-10-31 04:14:23+00:00  TyasAru14236593   \n",
       "1998  2022-10-31 04:13:44+00:00       rezkyheidi   \n",
       "1999  2022-10-31 04:13:18+00:00     everydaykkkk   \n",
       "\n",
       "                                                   Text  \\\n",
       "0     dulu di barat upn ada warung kayuh bambai bumb...   \n",
       "1          segala sakit yg disalahin vaksin covid lieur   \n",
       "2     bukankah kamu dulu bagian rezim namun setelah ...   \n",
       "3     aku kan ganti lama dulu sebelum covid menyeran...   \n",
       "4     trus masku kena covid lagi kek yah udah endemi...   \n",
       "...                                                 ...   \n",
       "1995  iya aku lebih merujuk kepada kerumunan faktor ...   \n",
       "1996  ayo vaksinagar tubuh terlindungi dari covid-19...   \n",
       "1997  bahkan kalo mau liat di lingkungan sekitar jug...   \n",
       "1998  min ada info lokasi tersedia untuk booster vak...   \n",
       "1999  saya puji tuhan ngga pernah kena covid bu tapi...   \n",
       "\n",
       "                                     Text_Clean_Sambung  \n",
       "0     dulu barat upn warung kayuh bambai bumbu haban...  \n",
       "1             segala sakit disalahin vaksin covid lieur  \n",
       "2     bukankah kamu dulu bagian rezim setelah terdep...  \n",
       "3     saya kan ganti lama dulu covid menyerang sudah...  \n",
       "4     terus  masku kena covid kek sudah  endemi masi ae  \n",
       "...                                                 ...  \n",
       "1995  iya saya lebih merujuk kepada kerumunan faktor...  \n",
       "1996  ayo vaksinagar tubuh terlindungi covid-19 ayo ...  \n",
       "1997  bahkan kalau  mau liat lingkungan banyak tetan...  \n",
       "1998      min info lokasi tersedia booster vaksin covid  \n",
       "1999  saya puji tuhan tidak  pernah kena covid bu ja...  \n",
       "\n",
       "[2000 rows x 4 columns]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **2.1 Menejermah Tweet Clean hasil Preproc ke Bahasa Inggris** (Translating)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install googletrans==4.0.0rc1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install google-cloud-translate==2.0.1\n",
    "%pip install --upgrade google-cloud-translate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## NOTE: JIKA MEMAKAI GOOGLE TRANSLATE API WEBSITE\n",
    "import pandas as pd\n",
    "from googletrans import Translator\n",
    "\n",
    "translator = Translator()\n",
    "\n",
    "translated_word = []\n",
    "new_row = []\n",
    "\n",
    "data = data.reset_index()  # make sure indexes pair with number of rows\n",
    "\n",
    "for index, row in data.iterrows():\n",
    "    new_row.append(row['Text_Clean_Sambung'])\n",
    "\n",
    "for per_row in new_row:\n",
    "    out = translator.translate(per_row, dest='en')\n",
    "    translated_word.append(out.text)\n",
    "\n",
    "data.insert(loc=len(data.columns),\n",
    "            column=\"text_english\", value=translated_word)\n",
    "\n",
    "print('Translating has completed!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## NOTE: JIKA MEMAKAI GOOGLE CLOUD TRANSLATE API\n",
    "import os\n",
    "\n",
    "from google.cloud import translate_v2\n",
    "\n",
    "os.environ['GOOGLE_APPLICATION_CREDENTIALS'] = r\"serviceKey.json\"\n",
    "\n",
    "translate_client = translate_v2.Client()\n",
    "\n",
    "text = \"Saya siapa dan kamu dimana\"\n",
    "\n",
    "target = \"en\"\n",
    "\n",
    "output = translate_client.translate(text, target_language=target)\n",
    "\n",
    "print(output)\n",
    "print(output['translatedText'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Translating has completed!\n"
     ]
    }
   ],
   "source": [
    "# REAL IMPLEMENTATION\n",
    "import os\n",
    "\n",
    "from google.cloud import translate_v2\n",
    "\n",
    "os.environ['GOOGLE_APPLICATION_CREDENTIALS'] = r\"serviceKey.json\"\n",
    "\n",
    "translate_client = translate_v2.Client()\n",
    "target = \"en\"\n",
    "\n",
    "translated_word = []\n",
    "new_row = []\n",
    "data = data.reset_index()  # make sure indexes pair with number of rows\n",
    "\n",
    "for index, row in data.iterrows():\n",
    "    new_row.append(row['Text_Clean_Sambung'])\n",
    "\n",
    "for per_row in new_row:\n",
    "    output = translate_client.translate(per_row, target_language=\"en\")\n",
    "    translated_word.append(output['translatedText'])\n",
    "\n",
    "data.insert(loc=len(data.columns),\n",
    "            column=\"text_english\", value=translated_word)\n",
    "\n",
    "print('Translating has completed!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>Tanggal</th>\n",
       "      <th>Username</th>\n",
       "      <th>Text</th>\n",
       "      <th>Text_Clean_Sambung</th>\n",
       "      <th>text_english</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>2022-10-31 23:59:58+00:00</td>\n",
       "      <td>lordkuyang</td>\n",
       "      <td>dulu di barat upn ada warung kayuh bambai bumb...</td>\n",
       "      <td>dulu barat upn warung kayuh bambai bumbu haban...</td>\n",
       "      <td>In the past, the western UPN stall, the caulif...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>2022-10-31 23:58:49+00:00</td>\n",
       "      <td>s_h_y_l_l_a</td>\n",
       "      <td>segala sakit yg disalahin vaksin covid lieur</td>\n",
       "      <td>segala sakit disalahin vaksin covid lieur</td>\n",
       "      <td>all illnesses are blamed for the covid lieur v...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>2022-10-31 23:58:14+00:00</td>\n",
       "      <td>kunsh72</td>\n",
       "      <td>bukankah kamu dulu bagian rezim namun setelah ...</td>\n",
       "      <td>bukankah kamu dulu bagian rezim setelah terdep...</td>\n",
       "      <td>Didn&amp;#39;t you used to be part of the regime a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>2022-10-31 23:57:58+00:00</td>\n",
       "      <td>erni076</td>\n",
       "      <td>aku kan ganti lama dulu sebelum covid menyeran...</td>\n",
       "      <td>saya kan ganti lama dulu covid menyerang sudah...</td>\n",
       "      <td>I changed it a long time ago, when Covid attac...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>2022-10-31 23:57:38+00:00</td>\n",
       "      <td>KENTUSIAS</td>\n",
       "      <td>trus masku kena covid lagi kek yah udah endemi...</td>\n",
       "      <td>terus  masku kena covid kek sudah  endemi masi ae</td>\n",
       "      <td>then my mask got covid kek it&amp;#39;s already en...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   index                    Tanggal     Username  \\\n",
       "0      0  2022-10-31 23:59:58+00:00   lordkuyang   \n",
       "1      1  2022-10-31 23:58:49+00:00  s_h_y_l_l_a   \n",
       "2      2  2022-10-31 23:58:14+00:00      kunsh72   \n",
       "3      3  2022-10-31 23:57:58+00:00      erni076   \n",
       "4      4  2022-10-31 23:57:38+00:00    KENTUSIAS   \n",
       "\n",
       "                                                Text  \\\n",
       "0  dulu di barat upn ada warung kayuh bambai bumb...   \n",
       "1       segala sakit yg disalahin vaksin covid lieur   \n",
       "2  bukankah kamu dulu bagian rezim namun setelah ...   \n",
       "3  aku kan ganti lama dulu sebelum covid menyeran...   \n",
       "4  trus masku kena covid lagi kek yah udah endemi...   \n",
       "\n",
       "                                  Text_Clean_Sambung  \\\n",
       "0  dulu barat upn warung kayuh bambai bumbu haban...   \n",
       "1          segala sakit disalahin vaksin covid lieur   \n",
       "2  bukankah kamu dulu bagian rezim setelah terdep...   \n",
       "3  saya kan ganti lama dulu covid menyerang sudah...   \n",
       "4  terus  masku kena covid kek sudah  endemi masi ae   \n",
       "\n",
       "                                        text_english  \n",
       "0  In the past, the western UPN stall, the caulif...  \n",
       "1  all illnesses are blamed for the covid lieur v...  \n",
       "2  Didn&#39;t you used to be part of the regime a...  \n",
       "3  I changed it a long time ago, when Covid attac...  \n",
       "4  then my mask got covid kek it&#39;s already en...  "
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# up to csv\n",
    "filename = \"english_tweets_covid_dataset_2k.csv\"\n",
    "data.to_csv(filename, index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **2.2 Stemming**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **3. Modelling Data** (Modeling and Training)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **4. Klasifikasi Data dengan Naive Bayes** (Classification)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.0 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "898a950986d43450680efc03f9903704e020e6e6b23d64c62a66308a081cc53c"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
