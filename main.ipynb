{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Projek Akhir Praktikum Data Science**\n",
    "\n",
    "> Analisis Sentimen Mengenai Vaksin COVID-19 Di Indonesia Menggunakan Metode Naive Bayes Classifier dan NLP Pada Sosial Media Twitter\n",
    "\n",
    "**Oleh Kelompok 2 :**\n",
    "1. Hazlan Muhammad Qodri (123190080) @hzlnqodrey\n",
    "2. Elisia Dwi Rahayu (123190062) @elisiadwirahayu\n",
    "3. Shania Septika Inayasari (123190055) @shaniainayasari\n",
    "\n",
    "**Penjelasan Projek :**\n",
    "\n",
    "Adapun pada penelitian menekankan kepada sentimen masyarakat terhadap mengenai vaksin COVID-19. Proses analisisnya akan dilakukan berdasarkan tweet yang menyertakan tagar vaksin dan pencarian di twitter dengan keyword vaksin covid 19."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **1. Scraping Data from Twitter**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: snscrape in c:\\users\\hazlan m qodri\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (0.4.3.20220106)\n",
      "Requirement already satisfied: beautifulsoup4 in c:\\users\\hazlan m qodri\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from snscrape) (4.10.0)\n",
      "Requirement already satisfied: filelock in c:\\users\\hazlan m qodri\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from snscrape) (3.8.0)\n",
      "Requirement already satisfied: lxml in c:\\users\\hazlan m qodri\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from snscrape) (4.9.1)\n",
      "Requirement already satisfied: requests[socks] in c:\\users\\hazlan m qodri\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from snscrape) (2.27.1)\n",
      "Requirement already satisfied: pytz in c:\\users\\hazlan m qodri\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from snscrape) (2020.1)\n",
      "Requirement already satisfied: soupsieve>1.2 in c:\\users\\hazlan m qodri\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from beautifulsoup4->snscrape) (2.3.1)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\users\\hazlan m qodri\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from requests[socks]->snscrape) (1.26.8)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\hazlan m qodri\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from requests[socks]->snscrape) (3.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\hazlan m qodri\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from requests[socks]->snscrape) (2021.10.8)\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0 in c:\\users\\hazlan m qodri\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from requests[socks]->snscrape) (2.0.12)\n",
      "Requirement already satisfied: PySocks!=1.5.7,>=1.5.6 in c:\\users\\hazlan m qodri\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from requests[socks]->snscrape) (1.7.1)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip available: 22.2.2 -> 22.3.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "%pip install snscrape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import snscrape.modules.twitter as sntwitter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get All Covid Sentiment Data from January 1st, 2020 until November 1st, 2022\n",
    "query = \"covid since:2020-01-01 until:2022-11-01 lang:id\"\n",
    "limit = 50000 # limit 50k rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\HAZLAN M QODRI\\AppData\\Local\\Temp\\ipykernel_11752\\3338915678.py:9: FutureWarning: username is deprecated, use user.username instead\n",
      "  tweet.username,\n"
     ]
    }
   ],
   "source": [
    "tweets = []\n",
    "\n",
    "for tweet in sntwitter.TwitterSearchScraper(query).get_items():\n",
    "    if len(tweets) == limit:\n",
    "        break\n",
    "    else:\n",
    "        tweets.append([\n",
    "            tweet.date,\n",
    "            tweet.username,\n",
    "            tweet.content\n",
    "        ])\n",
    "\n",
    "filename = 'tweets_covid_dataset_50k_raw.csv'\n",
    "tweets_df = pd.DataFrame(tweets, columns=['Tanggal', 'Username', 'Text'])\n",
    "tweets_df.to_csv(filename)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **2. Wrangling Data** (Preprocessing)\n",
    "\n",
    "##### 1. Case Folding\n",
    "##### 2. Cleaning\n",
    "##### 3. Tokenizing\n",
    "##### 4. Filtering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install tweet-preprocessor\n",
    "%pip install textblob\n",
    "%pip install wordcloud\n",
    "%pip install nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import preprocessor as preproc\n",
    "from textblob import TextBlob\n",
    "from nltk.stem import PorterStemmer\n",
    "from nltk.tokenize import word_tokenize\n",
    "import csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get data from dataset\n",
    "data = pd.read_csv('https://raw.githubusercontent.com/hzlnqodrey/projek-akhir-prak-ds-sentimen-analisis-twitter-covid19-nlp-bayes/main/tweets_covid_dataset_50k_raw.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 50000 entries, 0 to 49999\n",
      "Data columns (total 4 columns):\n",
      " #   Column      Non-Null Count  Dtype \n",
      "---  ------      --------------  ----- \n",
      " 0   Unnamed: 0  50000 non-null  int64 \n",
      " 1   Tanggal     50000 non-null  object\n",
      " 2   Username    50000 non-null  object\n",
      " 3   Text        50000 non-null  object\n",
      "dtypes: int64(1), object(3)\n",
      "memory usage: 1.5+ MB\n"
     ]
    }
   ],
   "source": [
    "data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>Tanggal</th>\n",
       "      <th>Username</th>\n",
       "      <th>Text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>25188</th>\n",
       "      <td>25188</td>\n",
       "      <td>2022-10-20 23:00:01+00:00</td>\n",
       "      <td>NoonaLateshia</td>\n",
       "      <td>Vaksinasi booster terbukti mampu meningkatkan ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22960</th>\n",
       "      <td>22960</td>\n",
       "      <td>2022-10-21 12:09:18+00:00</td>\n",
       "      <td>Rere_rhl</td>\n",
       "      <td>Ternyata bukan cuma gw yg ngerasa makin kesini...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21821</th>\n",
       "      <td>21821</td>\n",
       "      <td>2022-10-22 01:00:07+00:00</td>\n",
       "      <td>IAmRenegade1111</td>\n",
       "      <td>@tattyhassan Sebab vaksin la. Orang yang tak c...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30233</th>\n",
       "      <td>30233</td>\n",
       "      <td>2022-10-18 11:18:40+00:00</td>\n",
       "      <td>Anisyah_FDH</td>\n",
       "      <td>Yg angkatan covid rataÂ² kek gini ke gurunya ju...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>358</th>\n",
       "      <td>358</td>\n",
       "      <td>2022-10-31 15:26:55+00:00</td>\n",
       "      <td>teddybearkecik</td>\n",
       "      <td>@caaeeciil bjrittttt gwsss jgn covid</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Unnamed: 0                    Tanggal         Username  \\\n",
       "25188       25188  2022-10-20 23:00:01+00:00    NoonaLateshia   \n",
       "22960       22960  2022-10-21 12:09:18+00:00         Rere_rhl   \n",
       "21821       21821  2022-10-22 01:00:07+00:00  IAmRenegade1111   \n",
       "30233       30233  2022-10-18 11:18:40+00:00      Anisyah_FDH   \n",
       "358           358  2022-10-31 15:26:55+00:00   teddybearkecik   \n",
       "\n",
       "                                                    Text  \n",
       "25188  Vaksinasi booster terbukti mampu meningkatkan ...  \n",
       "22960  Ternyata bukan cuma gw yg ngerasa makin kesini...  \n",
       "21821  @tattyhassan Sebab vaksin la. Orang yang tak c...  \n",
       "30233  Yg angkatan covid rataÂ² kek gini ke gurunya ju...  \n",
       "358                 @caaeeciil bjrittttt gwsss jgn covid  "
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.sample(n=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **2.1 Stemming**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **2.2 Menejermah Tweet Clean hasil Preproc ke Bahasa Inggris** (Translating)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **3. Modelling Data** (Modeling and Training)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **4. Klasifikasi Data dengan Naive Bayes** (Classification)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.0 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "898a950986d43450680efc03f9903704e020e6e6b23d64c62a66308a081cc53c"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
