{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Projek Akhir Praktikum Data Science**\n",
    "\n",
    "> Analisis Sentimen Mengenai Vaksin COVID-19 Di Indonesia Menggunakan Metode Naive Bayes Classifier dan NLP Pada Sosial Media Twitter\n",
    "\n",
    "**Oleh Kelompok 2 :**\n",
    "1. Hazlan Muhammad Qodri (123190080) @hzlnqodrey\n",
    "2. Elisia Dwi Rahayu (123190062) @elisiadwirahayu\n",
    "3. Shania Septika Inayasari (123190055) @shaniainayasari\n",
    "\n",
    "**Penjelasan Projek :**\n",
    "\n",
    "Adapun pada penelitian menekankan kepada sentimen masyarakat terhadap mengenai vaksin COVID-19. Proses analisisnya akan dilakukan berdasarkan tweet yang menyertakan tagar vaksin dan pencarian di twitter dengan keyword vaksin covid 19."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **1. Scraping Data from Twitter**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: snscrape in c:\\users\\hazlan m qodri\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (0.4.3.20220106)\n",
      "Requirement already satisfied: beautifulsoup4 in c:\\users\\hazlan m qodri\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from snscrape) (4.10.0)\n",
      "Requirement already satisfied: filelock in c:\\users\\hazlan m qodri\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from snscrape) (3.8.0)\n",
      "Requirement already satisfied: lxml in c:\\users\\hazlan m qodri\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from snscrape) (4.9.1)\n",
      "Requirement already satisfied: requests[socks] in c:\\users\\hazlan m qodri\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from snscrape) (2.27.1)\n",
      "Requirement already satisfied: pytz in c:\\users\\hazlan m qodri\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from snscrape) (2020.1)\n",
      "Requirement already satisfied: soupsieve>1.2 in c:\\users\\hazlan m qodri\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from beautifulsoup4->snscrape) (2.3.1)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\users\\hazlan m qodri\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from requests[socks]->snscrape) (1.26.8)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\hazlan m qodri\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from requests[socks]->snscrape) (3.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\hazlan m qodri\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from requests[socks]->snscrape) (2021.10.8)\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0 in c:\\users\\hazlan m qodri\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from requests[socks]->snscrape) (2.0.12)\n",
      "Requirement already satisfied: PySocks!=1.5.7,>=1.5.6 in c:\\users\\hazlan m qodri\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from requests[socks]->snscrape) (1.7.1)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip available: 22.2.2 -> 22.3.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "%pip install snscrape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import snscrape.modules.twitter as sntwitter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get All Covid Sentiment Data from January 1st, 2020 until November 1st, 2022\n",
    "query = \"covid since:2020-01-01 until:2022-11-01 lang:id\"\n",
    "limit = 50000 # limit 50k rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\HAZLAN M QODRI\\AppData\\Local\\Temp\\ipykernel_11752\\3338915678.py:9: FutureWarning: username is deprecated, use user.username instead\n",
      "  tweet.username,\n"
     ]
    }
   ],
   "source": [
    "tweets = []\n",
    "\n",
    "for tweet in sntwitter.TwitterSearchScraper(query).get_items():\n",
    "    if len(tweets) == limit:\n",
    "        break\n",
    "    else:\n",
    "        tweets.append([\n",
    "            tweet.date,\n",
    "            tweet.username,\n",
    "            tweet.content\n",
    "        ])\n",
    "\n",
    "filename = 'tweets_covid_dataset_50k_raw.csv'\n",
    "tweets_df = pd.DataFrame(tweets, columns=['Tanggal', 'Username', 'Text'])\n",
    "tweets_df.to_csv(filename)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **2. Wrangling Data** (Preprocessing)\n",
    "\n",
    "##### 1. Case Folding\n",
    "##### 2. Cleaning\n",
    "##### 3. Tokenizing\n",
    "##### 4. Filtering\n",
    "##### 5. Stemming\n",
    "##### 6. Dropping Duplicate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install tweet-preprocessor\n",
    "%pip install textblob\n",
    "%pip install wordcloud\n",
    "%pip install nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import preprocessor as preproc\n",
    "from textblob import TextBlob\n",
    "from nltk.stem import PorterStemmer\n",
    "from nltk.tokenize import word_tokenize"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **2.1 Menejermah Tweet Clean hasil Preproc ke Bahasa Inggris** (Translating)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **3. Modelling Data** (Modeling and Training)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **4. Klasifikasi Data dengan Naive Bayes** (Classification)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.0 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "898a950986d43450680efc03f9903704e020e6e6b23d64c62a66308a081cc53c"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
